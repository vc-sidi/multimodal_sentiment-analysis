{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D \n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense \n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>415720</td>\n",
       "      <td>415720</td>\n",
       "      <td>800637990229815296-1</td>\n",
       "      <td>0.458655</td>\n",
       "      <td>0.435403</td>\n",
       "      <td>0.105942</td>\n",
       "      <td>@AskPlayStation my account got banned and I ha...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80063/800637990229815296-1.jpg</td>\n",
       "      <td>1536</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>15525</td>\n",
       "      <td>15525</td>\n",
       "      <td>769032642893320193-1</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.061676</td>\n",
       "      <td>0.929181</td>\n",
       "      <td>RT @morgan_price13: It was an awesome night!❤️...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>data/76903/769032642893320193-1.jpg</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>362371</td>\n",
       "      <td>362371</td>\n",
       "      <td>796804216022962180-1</td>\n",
       "      <td>0.829711</td>\n",
       "      <td>0.111822</td>\n",
       "      <td>0.058466</td>\n",
       "      <td>???????? I Fuck It Up Every Time #KingyPhotos ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79680/796804216022962180-1.jpg</td>\n",
       "      <td>2048</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>231955</td>\n",
       "      <td>231955</td>\n",
       "      <td>782437948889272320-1</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.112420</td>\n",
       "      <td>0.880838</td>\n",
       "      <td>Learning to say goodbye—w https://t.co/VOCIFWe...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>data/78243/782437948889272320-1.jpg</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>329462</td>\n",
       "      <td>329462</td>\n",
       "      <td>784522857715994627-1</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>0.929183</td>\n",
       "      <td>Happy birthday Sarah!! Ilysm and I hope your d...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>data/78452/784522857715994627-1.jpg</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>353043</td>\n",
       "      <td>353043</td>\n",
       "      <td>796218410174713856-1</td>\n",
       "      <td>0.716052</td>\n",
       "      <td>0.226798</td>\n",
       "      <td>0.057150</td>\n",
       "      <td>Can't Stump The Trump! ????????????❤️ https://...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79621/796218410174713856-1.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8694</th>\n",
       "      <td>133271</td>\n",
       "      <td>133271</td>\n",
       "      <td>780536863803138048-1</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.880886</td>\n",
       "      <td>0.091256</td>\n",
       "      <td>got this in the mail today #emaw #wildcats htt...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/78053/780536863803138048-1.jpg</td>\n",
       "      <td>2048</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>388012</td>\n",
       "      <td>388012</td>\n",
       "      <td>798701773686853632-3</td>\n",
       "      <td>0.482745</td>\n",
       "      <td>0.404692</td>\n",
       "      <td>0.112563</td>\n",
       "      <td>Here are selfies I never posted before https:/...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79870/798701773686853632-3.jpg</td>\n",
       "      <td>1365</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11149</th>\n",
       "      <td>113094</td>\n",
       "      <td>113094</td>\n",
       "      <td>769571837449740288-1</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.911801</td>\n",
       "      <td>0.078164</td>\n",
       "      <td>RT @keyannaaaaw: when she say she got the free...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/76957/769571837449740288-1.jpg</td>\n",
       "      <td>1149</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>123187</td>\n",
       "      <td>123187</td>\n",
       "      <td>780390402889220096-1</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.956680</td>\n",
       "      <td>Come out for the PTO Family Fun Night! Tons of...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>data/78039/780390402889220096-1.jpg</td>\n",
       "      <td>2048</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "1101       415720        415720  800637990229815296-1  0.458655  0.435403   \n",
       "6025        15525         15525  769032642893320193-1  0.009142  0.061676   \n",
       "1720       362371        362371  796804216022962180-1  0.829711  0.111822   \n",
       "4753       231955        231955  782437948889272320-1  0.006742  0.112420   \n",
       "4728       329462        329462  784522857715994627-1  0.017643  0.053174   \n",
       "...           ...           ...                   ...       ...       ...   \n",
       "1719       353043        353043  796218410174713856-1  0.716052  0.226798   \n",
       "8694       133271        133271  780536863803138048-1  0.027858  0.880886   \n",
       "2772       388012        388012  798701773686853632-3  0.482745  0.404692   \n",
       "11149      113094        113094  769571837449740288-1  0.010035  0.911801   \n",
       "4881       123187        123187  780390402889220096-1  0.005437  0.037882   \n",
       "\n",
       "            POS                                               text sent_text  \\\n",
       "1101   0.105942  @AskPlayStation my account got banned and I ha...       NEG   \n",
       "6025   0.929181  RT @morgan_price13: It was an awesome night!❤️...       POS   \n",
       "1720   0.058466  ???????? I Fuck It Up Every Time #KingyPhotos ...       NEG   \n",
       "4753   0.880838  Learning to say goodbye—w https://t.co/VOCIFWe...       POS   \n",
       "4728   0.929183  Happy birthday Sarah!! Ilysm and I hope your d...       POS   \n",
       "...         ...                                                ...       ...   \n",
       "1719   0.057150  Can't Stump The Trump! ????????????❤️ https://...       NEG   \n",
       "8694   0.091256  got this in the mail today #emaw #wildcats htt...       NEU   \n",
       "2772   0.112563  Here are selfies I never posted before https:/...       NEG   \n",
       "11149  0.078164  RT @keyannaaaaw: when she say she got the free...       NEU   \n",
       "4881   0.956680  Come out for the PTO Family Fun Night! Tons of...       POS   \n",
       "\n",
       "       sent_image                           image_path  image_height  \\\n",
       "1101            0  data/80063/800637990229815296-1.jpg          1536   \n",
       "6025            2  data/76903/769032642893320193-1.jpg          2048   \n",
       "1720            0  data/79680/796804216022962180-1.jpg          2048   \n",
       "4753            2  data/78243/782437948889272320-1.jpg           768   \n",
       "4728            2  data/78452/784522857715994627-1.jpg          1080   \n",
       "...           ...                                  ...           ...   \n",
       "1719            0  data/79621/796218410174713856-1.jpg          1024   \n",
       "8694            1  data/78053/780536863803138048-1.jpg          2048   \n",
       "2772            0  data/79870/798701773686853632-3.jpg          1365   \n",
       "11149           1  data/76957/769571837449740288-1.jpg          1149   \n",
       "4881            2  data/78039/780390402889220096-1.jpg          2048   \n",
       "\n",
       "       image_width  \n",
       "1101          2048  \n",
       "6025          1536  \n",
       "1720          1365  \n",
       "4753          1024  \n",
       "4728          1920  \n",
       "...            ...  \n",
       "1719           576  \n",
       "8694          1536  \n",
       "2772          2048  \n",
       "11149          749  \n",
       "4881          1526  \n",
       "\n",
       "[12000 rows x 12 columns]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path512 = \"dataset_sidi_512.csv\"\n",
    "path = \"dataset_sidi_v1.2.csv\"\n",
    "df512 = pd.read_csv(path512, sep='\\t')\n",
    "\n",
    "#so com duas classes\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "df512 = shuffle(df512)\n",
    "df512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODA\n",
    "#filenames = ['./Dataset/b-t4sa_imgs/' + fname for fname in df512['image_path'].tolist()]\n",
    "\n",
    "#Reduzido\n",
    "filenames = ['./Dataset512/' + fname+\".jpg\" for fname in df512['image_name'].tolist()]\n",
    "\n",
    "labels = df512['sent_image'].tolist()\n",
    "#labels = [1 if i==2 else i  for i in labels]\n",
    "\n",
    "x_train, val_filenames, y_train, val_labels = train_test_split(filenames,labels, train_size=0.8,random_state=42)\n",
    "\n",
    "x_val, x_test_filename, y_val, y_test = train_test_split(val_filenames,val_labels, train_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 1200, 1200)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len( y_val), len( y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n",
    "\n",
    "#sem utilizar os pesos\n",
    "base_model = VGG19(weights=None, include_top=False, input_shape=(width, height, channels))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 24579     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,048,963\n",
      "Trainable params: 20,048,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = layers.Flatten()\n",
    "prediction_layer = layers.Dense(3, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#opt =tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000002)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#busca os dados que estão listados em train_filenames\n",
    "import random\n",
    "def generate_data(train_filenames,train_labels, batch_size):\n",
    "\n",
    "    width = 128\n",
    "    height = 128\n",
    "    dim = (width, height)\n",
    "    while True:\n",
    "        \n",
    "        mistura = list(zip(train_filenames, train_labels))\n",
    "        \n",
    "        random.shuffle(mistura)\n",
    "\n",
    "        train_filenames, train_labels = zip(*mistura)\n",
    "        for i in range(0,len(train_filenames),batch_size):\n",
    "            \n",
    "            X_train = np.zeros((int(batch_size), width, height, 3))\n",
    "            aux =0\n",
    "\n",
    "            dim = (width, height)\n",
    "\n",
    "            for j in train_filenames[i:i+batch_size]:\n",
    "                X_train[aux] =  np.asarray(cv2.resize(cv2.imread(j), dim, interpolation = cv2.INTER_AREA) )\n",
    "                aux = aux + 1\n",
    "                \n",
    "            img = X_train.reshape(( X_train.shape[0],) +(width, height,3)).astype('float32') / 255.\n",
    "            #img = preprocess_input(img) \n",
    "            \n",
    "            yield (img, np.array(train_labels[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dobra para 48 pra vê se tanka\n",
    "\n",
    "batch_size=24\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "400/400 [==============================] - 48s 118ms/step - loss: 1.0986 - accuracy: 0.3332 - val_loss: 1.0986 - val_accuracy: 0.3517\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 49s 122ms/step - loss: 1.0983 - accuracy: 0.3348 - val_loss: 1.0981 - val_accuracy: 0.3542\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 49s 123ms/step - loss: 1.0969 - accuracy: 0.3527 - val_loss: 1.0952 - val_accuracy: 0.3650\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0940 - accuracy: 0.3705 - val_loss: 1.0929 - val_accuracy: 0.3642\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 1.0924 - accuracy: 0.3711 - val_loss: 1.0920 - val_accuracy: 0.3725\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 60s 150ms/step - loss: 1.0914 - accuracy: 0.3736 - val_loss: 1.0914 - val_accuracy: 0.3700\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0905 - accuracy: 0.3760 - val_loss: 1.0908 - val_accuracy: 0.3733\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0896 - accuracy: 0.3779 - val_loss: 1.0901 - val_accuracy: 0.3683\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0884 - accuracy: 0.3806 - val_loss: 1.0894 - val_accuracy: 0.3675\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0872 - accuracy: 0.3835 - val_loss: 1.0886 - val_accuracy: 0.3683\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0860 - accuracy: 0.3884 - val_loss: 1.0878 - val_accuracy: 0.3658\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 60s 150ms/step - loss: 1.0848 - accuracy: 0.3905 - val_loss: 1.0869 - val_accuracy: 0.3658\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 57s 142ms/step - loss: 1.0836 - accuracy: 0.3931 - val_loss: 1.0860 - val_accuracy: 0.3750\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0823 - accuracy: 0.3970 - val_loss: 1.0850 - val_accuracy: 0.3800\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0809 - accuracy: 0.3996 - val_loss: 1.0839 - val_accuracy: 0.3817\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0794 - accuracy: 0.4041 - val_loss: 1.0827 - val_accuracy: 0.3842\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 52s 131ms/step - loss: 1.0779 - accuracy: 0.4053 - val_loss: 1.0819 - val_accuracy: 0.3950\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 54s 134ms/step - loss: 1.0765 - accuracy: 0.4081 - val_loss: 1.0813 - val_accuracy: 0.4067\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0753 - accuracy: 0.4117 - val_loss: 1.0808 - val_accuracy: 0.4033\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0742 - accuracy: 0.4151 - val_loss: 1.0803 - val_accuracy: 0.4108\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 51s 126ms/step - loss: 1.0732 - accuracy: 0.4164 - val_loss: 1.0798 - val_accuracy: 0.4108\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 1.0723 - accuracy: 0.4173 - val_loss: 1.0794 - val_accuracy: 0.4025\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 60s 149ms/step - loss: 1.0714 - accuracy: 0.4198 - val_loss: 1.0790 - val_accuracy: 0.4100\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 52s 130ms/step - loss: 1.0705 - accuracy: 0.4199 - val_loss: 1.0787 - val_accuracy: 0.4125\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 51s 126ms/step - loss: 1.0696 - accuracy: 0.4224 - val_loss: 1.0785 - val_accuracy: 0.4117\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 52s 131ms/step - loss: 1.0688 - accuracy: 0.4233 - val_loss: 1.0783 - val_accuracy: 0.4183\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 51s 127ms/step - loss: 1.0679 - accuracy: 0.4253 - val_loss: 1.0781 - val_accuracy: 0.4192\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 60s 150ms/step - loss: 1.0670 - accuracy: 0.4278 - val_loss: 1.0781 - val_accuracy: 0.4183\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 59s 149ms/step - loss: 1.0661 - accuracy: 0.4300 - val_loss: 1.0780 - val_accuracy: 0.4133\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 51s 126ms/step - loss: 1.0652 - accuracy: 0.4304 - val_loss: 1.0779 - val_accuracy: 0.4158\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 52s 130ms/step - loss: 1.0642 - accuracy: 0.4316 - val_loss: 1.0779 - val_accuracy: 0.4133\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 1.0632 - accuracy: 0.4335 - val_loss: 1.0780 - val_accuracy: 0.4083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac3fcbb190>"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=2,  restore_best_weights=True)\n",
    "epocas = 500\n",
    "\n",
    "model.fit( generate_data(x_train, y_train, batch_size),validation_steps=50,steps_per_epoch=400, callbacks=[es],\n",
    "        batch_size=batch_size,  epochs=epocas,validation_data=generate_data(x_val,y_val, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.zeros((len(y_test), width, height, 3))\n",
    "aux =0\n",
    "\n",
    "dim = (width, height)\n",
    "\n",
    "for i in x_test_filename:\n",
    "    x_test[aux] = np.asarray(cv2.resize(cv2.imread(i), dim, interpolation = cv2.INTER_AREA) )\n",
    "    aux = aux + 1\n",
    "x_test = x_test.reshape((x_test.shape[0],) +(width, height,3)).astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4091666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.33      0.39       411\n",
      "           1       0.40      0.55      0.46       402\n",
      "           2       0.37      0.35      0.36       387\n",
      "\n",
      "    accuracy                           0.41      1200\n",
      "   macro avg       0.42      0.41      0.40      1200\n",
      "weighted avg       0.42      0.41      0.40      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "test_labels_result= np.argmax(y_test, axis=-1)\n",
    "\n",
    "print(accuracy_score(test_labels_result, y_pred));\n",
    "print(classification_report(test_labels_result, y_pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativo - 0     Neutro - 1      Positivo - 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Negativo - 0     Neutro - 1      Positivo - 2\")\n",
    "sns.heatmap(confusion_matrix(test_labels_result, y_pred), annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
