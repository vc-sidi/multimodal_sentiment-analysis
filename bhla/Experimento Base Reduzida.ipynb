{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\bhla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "additional  = ['rt','rts','retweet'] # lista adicional de stopwords\n",
    "swords = set().union(stopwords.words('english'),additional) # adicionando palavras para o stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443004</td>\n",
       "      <td>443004</td>\n",
       "      <td>802556641057054721-1</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.304103</td>\n",
       "      <td>0.155888</td>\n",
       "      <td>No cheat just skill. #ClikerHeroes https://t.c...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80255/802556641057054721-1.jpg</td>\n",
       "      <td>707</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348885</td>\n",
       "      <td>348885</td>\n",
       "      <td>796032212407721984-1</td>\n",
       "      <td>0.513661</td>\n",
       "      <td>0.322456</td>\n",
       "      <td>0.163883</td>\n",
       "      <td>@KEILOin_DaTrunk I deleted https://t.co/qIhBkn...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79603/796032212407721984-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377487</td>\n",
       "      <td>377487</td>\n",
       "      <td>798011160532381696-1</td>\n",
       "      <td>0.712648</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>\"RT NYTFashion: How Nasty Gal went from an eBa...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79801/798011160532381696-1.jpg</td>\n",
       "      <td>561</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423703</td>\n",
       "      <td>423703</td>\n",
       "      <td>801181521679790080-1</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>I hate this nigga lmaooo https://t.co/gPcyJfJESN</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80118/801181521679790080-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>108284</td>\n",
       "      <td>108284</td>\n",
       "      <td>769551952275509248-1</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.886504</td>\n",
       "      <td>0.102978</td>\n",
       "      <td>RT @Alwas97: find someone who loves you like b...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/76955/769551952275509248-1.jpg</td>\n",
       "      <td>1218</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>93186</td>\n",
       "      <td>93186</td>\n",
       "      <td>769486781158858753-1</td>\n",
       "      <td>0.065240</td>\n",
       "      <td>0.897818</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>RT @MelbWritersFest: Helen Garner talking to @...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/76948/769486781158858753-1.jpg</td>\n",
       "      <td>1491</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>298145</td>\n",
       "      <td>298145</td>\n",
       "      <td>783915769943973890-1</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>0.925276</td>\n",
       "      <td>0.063257</td>\n",
       "      <td>Watch lesbian movie: https://t.co/jzJrDcnAwaSh...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/78391/783915769943973890-1.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>260672</td>\n",
       "      <td>260672</td>\n",
       "      <td>783138720610476033-1</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.957911</td>\n",
       "      <td>0.039016</td>\n",
       "      <td>Click here to watch the movie:  https://t.co/A...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/78313/783138720610476033-1.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>315469</td>\n",
       "      <td>315469</td>\n",
       "      <td>784250546710380544-1</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.882548</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>Did you notice defn has a brand new logo desig...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/78425/784250546710380544-1.jpg</td>\n",
       "      <td>1106</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0          382583        382583  798338609870872577-2  0.774375  0.174701   \n",
       "1          443004        443004  802556641057054721-1  0.540009  0.304103   \n",
       "2          348885        348885  796032212407721984-1  0.513661  0.322456   \n",
       "3          377487        377487  798011160532381696-1  0.712648  0.254173   \n",
       "4          423703        423703  801181521679790080-1  0.713677  0.186854   \n",
       "...           ...           ...                   ...       ...       ...   \n",
       "11995      108284        108284  769551952275509248-1  0.010517  0.886504   \n",
       "11996       93186         93186  769486781158858753-1  0.065240  0.897818   \n",
       "11997      298145        298145  783915769943973890-1  0.011468  0.925276   \n",
       "11998      260672        260672  783138720610476033-1  0.003072  0.957911   \n",
       "11999      315469        315469  784250546710380544-1  0.013852  0.882548   \n",
       "\n",
       "            POS                                               text sent_text  \\\n",
       "0      0.050924  what does it look like i do for a living? (cra...       NEG   \n",
       "1      0.155888  No cheat just skill. #ClikerHeroes https://t.c...       NEG   \n",
       "2      0.163883  @KEILOin_DaTrunk I deleted https://t.co/qIhBkn...       NEG   \n",
       "3      0.033180  \"RT NYTFashion: How Nasty Gal went from an eBa...       NEG   \n",
       "4      0.099468   I hate this nigga lmaooo https://t.co/gPcyJfJESN       NEG   \n",
       "...         ...                                                ...       ...   \n",
       "11995  0.102978  RT @Alwas97: find someone who loves you like b...       NEU   \n",
       "11996  0.036942  RT @MelbWritersFest: Helen Garner talking to @...       NEU   \n",
       "11997  0.063257  Watch lesbian movie: https://t.co/jzJrDcnAwaSh...       NEU   \n",
       "11998  0.039016  Click here to watch the movie:  https://t.co/A...       NEU   \n",
       "11999  0.103600  Did you notice defn has a brand new logo desig...       NEU   \n",
       "\n",
       "       sent_image                           image_path  image_height  \\\n",
       "0               0  data/79833/798338609870872577-2.jpg          1280   \n",
       "1               0  data/80255/802556641057054721-1.jpg           707   \n",
       "2               0  data/79603/796032212407721984-1.jpg          1334   \n",
       "3               0  data/79801/798011160532381696-1.jpg           561   \n",
       "4               0  data/80118/801181521679790080-1.jpg          1334   \n",
       "...           ...                                  ...           ...   \n",
       "11995           1  data/76955/769551952275509248-1.jpg          1218   \n",
       "11996           1  data/76948/769486781158858753-1.jpg          1491   \n",
       "11997           1  data/78391/783915769943973890-1.jpg          1024   \n",
       "11998           1  data/78313/783138720610476033-1.jpg          1024   \n",
       "11999           1  data/78425/784250546710380544-1.jpg          1106   \n",
       "\n",
       "       image_width  \n",
       "0              722  \n",
       "1             1366  \n",
       "2              750  \n",
       "3             1000  \n",
       "4              750  \n",
       "...            ...  \n",
       "11995         1078  \n",
       "11996         2048  \n",
       "11997          683  \n",
       "11998          682  \n",
       "11999         2048  \n",
       "\n",
       "[12000 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"dataset_sidi_v1.2.csv\"\n",
    "path512 = \"dataset_sidi_512.csv\"\n",
    "\n",
    "df512 = pd.read_csv(path512, sep='\\t')\n",
    "df512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout 80/10/10\n",
    "#Separando treino e parte para validação e teste\n",
    "x_train, x_split_two, y_train, y_split_two = train_test_split( df512, df512['sent_image'], train_size=0.8,random_state=42)\n",
    "#Separando teste e validação\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_split_two,y_split_two, train_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenização\n",
    "t  = Tokenizer()\n",
    "t.fit_on_texts(df512['text'].tolist())\n",
    "\n",
    "#Bi-LSTM\n",
    "x_train_BiLSTM = t.texts_to_sequences(x_train['text'].tolist())\n",
    "x_val_BiLSTM = t.texts_to_sequences(x_val['text'].tolist())\n",
    "x_test_BiLSTM = t.texts_to_sequences(x_test['text'].tolist())\n",
    "\n",
    "#VADER\n",
    "x_test_VADER = x_test[\"text\"]\n",
    "\n",
    "##VGG19\n",
    "x_train = ['./Dataset/b-t4sa_imgs/' + fname for fname in x_train['image_path'].tolist()]\n",
    "x_val = ['./Dataset/b-t4sa_imgs/' + fname for fname in x_val['image_path'].tolist()]\n",
    "x_test = ['./Dataset/b-t4sa_imgs/' + fname for fname in x_test['image_path'].tolist()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mudando o formato para suporta o softmax na rede\n",
    "#saindo do formato [2] para [0,0,1]\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "#y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_VADER_sentiment(tweet):\n",
    "\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet) #remove menções\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)  # remove hashtag\n",
    "   \n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text) \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    sentiment_dict = sid_obj.polarity_scores(tweet)\n",
    "\n",
    "        # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return 2\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return  0\n",
    " \n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_VADER = [tweet_to_VADER_sentiment(i) for i in x_test_VADER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "max_features = 10000\n",
    "x_train_BiLSTM = keras.preprocessing.sequence.pad_sequences(x_train_BiLSTM, maxlen=maxlen)\n",
    "x_val_BiLSTM = keras.preprocessing.sequence.pad_sequences(x_val_BiLSTM, maxlen=maxlen)\n",
    "x_test_BiLSTM = keras.preprocessing.sequence.pad_sequences(x_test_BiLSTM, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10893"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,478,019\n",
      "Trainable params: 1,478,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Arquitetura base da página https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "#Modificação feita na saida (3) e na acitivação da saida (solftmax)\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 4s 59ms/step - loss: 1.0016 - accuracy: 0.4790 - val_loss: 0.8609 - val_accuracy: 0.6625\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5243 - accuracy: 0.7997 - val_loss: 0.4258 - val_accuracy: 0.8475\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.1670 - accuracy: 0.9465 - val_loss: 0.3849 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 3.\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0689 - accuracy: 0.9803 - val_loss: 0.4682 - val_accuracy: 0.8617\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Compilando com lr de 0.001\n",
    "model.compile(Adam(learning_rate=0.001), \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#fazneodo early top quando o loss da validação aumentar\n",
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=1,restore_best_weights=True)\n",
    "\n",
    "#treinando\n",
    "history_BiLSTM = model.fit(x_train_BiLSTM, y_train, batch_size=300, epochs=20, validation_data=(x_val_BiLSTM, y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BiLSTM = model.predict(x_test_BiLSTM)\n",
    "y_pred_BiLSTM =(y_pred_BiLSTM>0.5)\n",
    "y_pred_BiLSTM = np.argmax(y_pred_BiLSTM, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 adaptada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para limpar memória\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights=None, include_top=False, input_shape=(width, height, channels))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1028)              8422404   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1028)              1057812   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3087      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,507,687\n",
      "Trainable params: 29,507,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer = layers.Flatten()\n",
    "dense1 = layers.Dense(1028, activation='relu')\n",
    "dense2 = layers.Dense(1028, activation='relu')\n",
    "prediction_layer = layers.Dense(3, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense1,\n",
    "    dense2,\n",
    "    prediction_layer\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000002)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#busca os dados que estão listados em train_filenames\n",
    "import random\n",
    "def generate_data(train_filenames,train_labels, batch_size,width, height,channels):\n",
    "    dim = (width, height)\n",
    "    while True:\n",
    "        \n",
    "        mistura = list(zip(train_filenames, train_labels))\n",
    "        random.shuffle(mistura)\n",
    "        train_filenames, train_labels = zip(*mistura)\n",
    "        \n",
    "        for i in range(0,len(train_filenames),batch_size):\n",
    "            \n",
    "            if  i+batch_size > len(train_filenames):\n",
    "                bs = len(train_filenames)%batch_size\n",
    "            else:\n",
    "                bs = batch_size\n",
    "            \n",
    "            X_train = np.zeros((int(bs), width, height, channels))\n",
    "            aux =0\n",
    "\n",
    "            dim = (width, height)\n",
    "\n",
    "            for j in train_filenames[i:i+ bs]:\n",
    "                X_train[aux] =  np.asarray(cv2.resize(cv2.imread(j), dim, interpolation = cv2.INTER_AREA) )\n",
    "                aux = aux + 1\n",
    "                \n",
    "            #img = X_train.reshape(( X_train.shape[0],) +(width, height,channels)).astype('float32') / 255.\n",
    "            img = preprocess_input( X_train) \n",
    "            \n",
    "            yield (img, np.array(train_labels[i:i+ bs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 34, 36)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dobra para 48 pra vê se tanka\n",
    "\n",
    "batch_size=36\n",
    "\n",
    "validation_steps = int(len(x_val)/batch_size)+(0 if len(x_val)%batch_size==0 else 1)\n",
    "steps_per_epoch = int(len(x_train)/batch_size)+(0 if len(x_train)%batch_size==0 else 1)\n",
    "steps_per_epoch,validation_steps,batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "267/267 [==============================] - 283s 1s/step - loss: 1.0973 - accuracy: 0.3436 - val_loss: 1.0934 - val_accuracy: 0.3642\n",
      "Epoch 2/500\n",
      "267/267 [==============================] - 283s 1s/step - loss: 1.0924 - accuracy: 0.3699 - val_loss: 1.0907 - val_accuracy: 0.3800\n",
      "Epoch 3/500\n",
      "267/267 [==============================] - 285s 1s/step - loss: 1.0881 - accuracy: 0.3824 - val_loss: 1.0882 - val_accuracy: 0.3883\n",
      "Epoch 4/500\n",
      "267/267 [==============================] - 288s 1s/step - loss: 1.0844 - accuracy: 0.3913 - val_loss: 1.0890 - val_accuracy: 0.3683\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=1,  restore_best_weights=True)\n",
    "epocas = 500\n",
    "\n",
    "history_VGG19 = model.fit( generate_data(x_train, y_train, batch_size,width, height,channels),\n",
    "          validation_steps=validation_steps,steps_per_epoch=steps_per_epoch,\n",
    "          callbacks=[es], batch_size=batch_size,  epochs=epocas,\n",
    "          validation_data=generate_data(x_val,y_val, batch_size,width, height,channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "##generator para teste pra tankar com rede maior\n",
    "def generate_data_teste(train_filenames, batch_size,width, height,channels):\n",
    "    dim = (width, height)\n",
    "    while True:\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(train_filenames),batch_size):\n",
    "            \n",
    "            if  i+batch_size > len(train_filenames):\n",
    "                bs = len(train_filenames)%batch_size\n",
    "            else:\n",
    "                bs = batch_size\n",
    "            \n",
    "            X_train = np.zeros((int(bs), width, height, channels))\n",
    "            aux =0\n",
    "\n",
    "            dim = (width, height)\n",
    "\n",
    "            for j in train_filenames[i:i+ bs]:\n",
    "                X_train[aux] =  np.asarray(cv2.resize(cv2.imread(j), dim, interpolation = cv2.INTER_AREA) )\n",
    "                aux = aux + 1\n",
    "                \n",
    "           # img = X_train.reshape(( X_train.shape[0],) +(width, height,channels)).astype('float32') / 255.\n",
    "            img = preprocess_input(X_train) \n",
    "            \n",
    "            yield (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vgg = model.predict(generate_data_teste(x_test,batch_size,width, height,channels),steps=validation_steps)\n",
    "\n",
    "y_pred_vgg = np.argmax(y_pred_vgg, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VADER</th>\n",
       "      <th>BiLSTM</th>\n",
       "      <th>BiLSTM_Peso_2</th>\n",
       "      <th>VGG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VADER  BiLSTM  BiLSTM_Peso_2  VGG\n",
       "0         0       2              2    1\n",
       "1         1       1              1    2\n",
       "2         2       0              0    1\n",
       "3         2       0              0    2\n",
       "4         0       1              1    2\n",
       "...     ...     ...            ...  ...\n",
       "1195      2       1              1    2\n",
       "1196      2       1              1    1\n",
       "1197      2       2              2    1\n",
       "1198      1       1              1    2\n",
       "1199      1       1              1    1\n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = pd.DataFrame()\n",
    "labels_pred[\"VADER\"] = y_pred_VADER\n",
    "labels_pred[\"BiLSTM\"] = y_pred_BiLSTM\n",
    "labels_pred[\"BiLSTM_Peso_2\"] = y_pred_BiLSTM\n",
    "labels_pred[\"VGG\"] = y_pred_vgg\n",
    "labels_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "moda = labels_pred.mode(axis =1)\n",
    "y_pred = moda[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       420\n",
      "           1       0.89      0.80      0.84       374\n",
      "           2       0.91      0.88      0.90       406\n",
      "\n",
      "    accuracy                           0.87      1200\n",
      "   macro avg       0.88      0.87      0.87      1200\n",
      "weighted avg       0.88      0.87      0.87      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred));\n",
    "print(classification_report(y_test, y_pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativo - 0     Neutro - 1      Positivo - 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Negativo - 0     Neutro - 1      Positivo - 2\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia de cada classe\n",
      "Negativo - 0     Neutro - 1      Positivo - 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.79679144, 0.88423645])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = confusion_matrix(y_test, y_pred)\n",
    "print(\"Acuracia de cada classe\")\n",
    "print(\"Negativo - 0     Neutro - 1      Positivo - 2\")\n",
    "m.diagonal()/m.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
