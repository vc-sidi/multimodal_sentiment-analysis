{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umln0h6MLQqD",
    "tags": []
   },
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rbsa2\\AppData\\Local\\Temp/ipykernel_7472/2828644452.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4091289943419823830\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2252026676\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17073572025521127408\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "type(gpus)\n",
    "if gpus:\n",
    "  # Replicate your computation on multiple GPUs\n",
    "  c = []\n",
    "  for gpu in gpus:\n",
    "    with tf.device(gpu.name):\n",
    "        print(gpu.name)\n",
    "        pass\n",
    "gpu = gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('./')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "import h5py\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import Input\n",
    "from tensorflow.keras import optimizers\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "import sklearn.metrics as sklm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KSRqGGEH2_Ny"
   },
   "outputs": [],
   "source": [
    "CHARNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/charcnn_data_config.json\"\n",
    "charcnn_data_config = pd.read_json(CHARNN_DATA_CONFIG)\n",
    "\n",
    "CNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/nn_config.json\"\n",
    "nn_data_config = pd.read_json(CNN_DATA_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "94AqsbHfVdB1"
   },
   "outputs": [],
   "source": [
    "#data_config = json.load(open(\"charcnn_data_config.json\")) #Leitura do arquivo de configuracao\n",
    "data_config = charcnn_data_config #Leitura do arquivo de configuracao\n",
    "\n",
    "#nn_config = json.load(open(\"nn_config.json\")) # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "nn_config = nn_data_config # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "\n",
    "alphabet_size = data_config[\"data\"][\"alphabet_size\"]+1 #tamanho do alfabeto\n",
    "input_size = data_config[\"data\"][\"input_size\"] #Tamanho do input de zi\n",
    "\n",
    "fully_connected_layers = nn_config[\"char_cnn_zhang\"][\"fully_connected_layers\"] #Camadas Conectadas\n",
    "conv_layers = nn_config[\"char_cnn_zhang\"][\"conv_layers\"] #Camadas Convulacionasi\n",
    "threshold = nn_config[\"char_cnn_zhang\"][\"threshold\"] # Limiar\n",
    "dropout_p = nn_config[\"char_cnn_zhang\"][\"dropout_p\"] #Taxa de Dropout\n",
    "embedding_size = nn_config[\"char_cnn_zhang\"][\"embedding_size\"] # Tamnho do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uFSgTy5kVdB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_URL  = \"D:/SiDi/Project/Modulo II/dataset/dataset_sidi_512.csv\"\n",
    "df = pd.read_csv(DATASET_PATH_URL, sep='\\t')\n",
    "\n",
    "print(len(df))\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0      0      382583        382583  798338609870872577-2  0.774375  0.174701   \n",
       "\n",
       "        POS                                               text sent_text  \\\n",
       "0  0.050924  what does it look like i do for a living? (cra...       NEG   \n",
       "\n",
       "   sent_image                           image_path  image_height  image_width  \n",
       "0           0  data/79833/798338609870872577-2.jpg          1280          722  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>8001</td>\n",
       "      <td>84282</td>\n",
       "      <td>84282</td>\n",
       "      <td>769436550190948352-1</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.943351</td>\n",
       "      <td>0.04025</td>\n",
       "      <td>RT @NoHoesAdam: Thinking about how many times ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>data/76943/769436550190948352-1.jpg</td>\n",
       "      <td>1138</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0  Unnamed: 0.1            image_name       NEG  \\\n",
       "8001   8001       84282         84282  769436550190948352-1  0.016399   \n",
       "\n",
       "           NEU      POS                                               text  \\\n",
       "8001  0.943351  0.04025  RT @NoHoesAdam: Thinking about how many times ...   \n",
       "\n",
       "     sent_text  sent_image                           image_path  image_height  \\\n",
       "8001       NEU           1  data/76943/769436550190948352-1.jpg          1138   \n",
       "\n",
       "      image_width  \n",
       "8001          960  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[8001:8002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>4001</td>\n",
       "      <td>261866</td>\n",
       "      <td>261866</td>\n",
       "      <td>783159977338736640-1</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>0.931898</td>\n",
       "      <td>Keystagram: Umm superfreak sounds good like me...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>data/78315/783159977338736640-1.jpg</td>\n",
       "      <td>936</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0  Unnamed: 0.1            image_name       NEG  \\\n",
       "4001   4001      261866        261866  783159977338736640-1  0.013936   \n",
       "\n",
       "           NEU       POS                                               text  \\\n",
       "4001  0.054167  0.931898  Keystagram: Umm superfreak sounds good like me...   \n",
       "\n",
       "     sent_text  sent_image                           image_path  image_height  \\\n",
       "4001       POS           2  data/78315/783159977338736640-1.jpg           936   \n",
       "\n",
       "      image_width  \n",
       "4001          750  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[4001:4002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0      0      382583        382583  798338609870872577-2  0.774375  0.174701   \n",
       "\n",
       "        POS                                               text sent_text  \\\n",
       "0  0.050924  what does it look like i do for a living? (cra...       NEG   \n",
       "\n",
       "   sent_image                           image_path  image_height  image_width  \n",
       "0           0  data/79833/798338609870872577-2.jpg          1280          722  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>443004</td>\n",
       "      <td>443004</td>\n",
       "      <td>802556641057054721-1</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.304103</td>\n",
       "      <td>0.155888</td>\n",
       "      <td>No cheat just skill. #ClikerHeroes https://t.c...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80255/802556641057054721-1.jpg</td>\n",
       "      <td>707</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>348885</td>\n",
       "      <td>348885</td>\n",
       "      <td>796032212407721984-1</td>\n",
       "      <td>0.513661</td>\n",
       "      <td>0.322456</td>\n",
       "      <td>0.163883</td>\n",
       "      <td>@KEILOin_DaTrunk I deleted https://t.co/qIhBkn...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79603/796032212407721984-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>377487</td>\n",
       "      <td>377487</td>\n",
       "      <td>798011160532381696-1</td>\n",
       "      <td>0.712648</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>\"RT NYTFashion: How Nasty Gal went from an eBa...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79801/798011160532381696-1.jpg</td>\n",
       "      <td>561</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>423703</td>\n",
       "      <td>423703</td>\n",
       "      <td>801181521679790080-1</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>I hate this nigga lmaooo https://t.co/gPcyJfJESN</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80118/801181521679790080-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>366928</td>\n",
       "      <td>366928</td>\n",
       "      <td>797124816012791809-3</td>\n",
       "      <td>0.734435</td>\n",
       "      <td>0.182342</td>\n",
       "      <td>0.083223</td>\n",
       "      <td>What about this one? Is she worth a fuck? http...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79712/797124816012791809-3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>388716</td>\n",
       "      <td>388716</td>\n",
       "      <td>798744236803899392-1</td>\n",
       "      <td>0.750881</td>\n",
       "      <td>0.104132</td>\n",
       "      <td>0.144987</td>\n",
       "      <td>I swear. Listen to it. If you wanna be in a sa...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79874/798744236803899392-1.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>409502</td>\n",
       "      <td>409502</td>\n",
       "      <td>800191074538901504-1</td>\n",
       "      <td>0.819542</td>\n",
       "      <td>0.138484</td>\n",
       "      <td>0.041973</td>\n",
       "      <td>I don't remember taking this photo but I proba...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80019/800191074538901504-1.jpg</td>\n",
       "      <td>2048</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>305785</td>\n",
       "      <td>305785</td>\n",
       "      <td>784074855704559616-1</td>\n",
       "      <td>0.926570</td>\n",
       "      <td>0.045142</td>\n",
       "      <td>0.028288</td>\n",
       "      <td>@SVS_Sound Y'all know that you're mad geniuses...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/78407/784074855704559616-1.jpg</td>\n",
       "      <td>518</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>462605</td>\n",
       "      <td>462605</td>\n",
       "      <td>803960344565739524-1</td>\n",
       "      <td>0.652385</td>\n",
       "      <td>0.234284</td>\n",
       "      <td>0.113331</td>\n",
       "      <td>Had to unfollow...y'all weird &amp;amp; poor https...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80396/803960344565739524-1.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Unnamed: 0  Unnamed: 0.1            image_name       NEG  \\\n",
       "0        0      382583        382583  798338609870872577-2  0.774375   \n",
       "1        1      443004        443004  802556641057054721-1  0.540009   \n",
       "2        2      348885        348885  796032212407721984-1  0.513661   \n",
       "3        3      377487        377487  798011160532381696-1  0.712648   \n",
       "4        4      423703        423703  801181521679790080-1  0.713677   \n",
       "..     ...         ...           ...                   ...       ...   \n",
       "995    995      366928        366928  797124816012791809-3  0.734435   \n",
       "996    996      388716        388716  798744236803899392-1  0.750881   \n",
       "997    997      409502        409502  800191074538901504-1  0.819542   \n",
       "998    998      305785        305785  784074855704559616-1  0.926570   \n",
       "999    999      462605        462605  803960344565739524-1  0.652385   \n",
       "\n",
       "          NEU       POS                                               text  \\\n",
       "0    0.174701  0.050924  what does it look like i do for a living? (cra...   \n",
       "1    0.304103  0.155888  No cheat just skill. #ClikerHeroes https://t.c...   \n",
       "2    0.322456  0.163883  @KEILOin_DaTrunk I deleted https://t.co/qIhBkn...   \n",
       "3    0.254173  0.033180  \"RT NYTFashion: How Nasty Gal went from an eBa...   \n",
       "4    0.186854  0.099468   I hate this nigga lmaooo https://t.co/gPcyJfJESN   \n",
       "..        ...       ...                                                ...   \n",
       "995  0.182342  0.083223  What about this one? Is she worth a fuck? http...   \n",
       "996  0.104132  0.144987  I swear. Listen to it. If you wanna be in a sa...   \n",
       "997  0.138484  0.041973  I don't remember taking this photo but I proba...   \n",
       "998  0.045142  0.028288  @SVS_Sound Y'all know that you're mad geniuses...   \n",
       "999  0.234284  0.113331  Had to unfollow...y'all weird &amp; poor https...   \n",
       "\n",
       "    sent_text  sent_image                           image_path  image_height  \\\n",
       "0         NEG           0  data/79833/798338609870872577-2.jpg          1280   \n",
       "1         NEG           0  data/80255/802556641057054721-1.jpg           707   \n",
       "2         NEG           0  data/79603/796032212407721984-1.jpg          1334   \n",
       "3         NEG           0  data/79801/798011160532381696-1.jpg           561   \n",
       "4         NEG           0  data/80118/801181521679790080-1.jpg          1334   \n",
       "..        ...         ...                                  ...           ...   \n",
       "995       NEG           0  data/79712/797124816012791809-3.jpg          1024   \n",
       "996       NEG           0  data/79874/798744236803899392-1.jpg          1024   \n",
       "997       NEG           0  data/80019/800191074538901504-1.jpg          2048   \n",
       "998       NEG           0  data/78407/784074855704559616-1.jpg           518   \n",
       "999       NEG           0  data/80396/803960344565739524-1.jpg          1024   \n",
       "\n",
       "     image_width  \n",
       "0            722  \n",
       "1           1366  \n",
       "2            750  \n",
       "3           1000  \n",
       "4            750  \n",
       "..           ...  \n",
       "995          575  \n",
       "996          576  \n",
       "997         1152  \n",
       "998          598  \n",
       "999          830  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sent_image']).get_group(0)[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbsa2\\AppData\\Local\\Temp/ipykernel_7472/2168241912.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df.groupby(['sent_image']).head()[df['sent_image'] == 0 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>443004</td>\n",
       "      <td>443004</td>\n",
       "      <td>802556641057054721-1</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.304103</td>\n",
       "      <td>0.155888</td>\n",
       "      <td>No cheat just skill. #ClikerHeroes https://t.c...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80255/802556641057054721-1.jpg</td>\n",
       "      <td>707</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>348885</td>\n",
       "      <td>348885</td>\n",
       "      <td>796032212407721984-1</td>\n",
       "      <td>0.513661</td>\n",
       "      <td>0.322456</td>\n",
       "      <td>0.163883</td>\n",
       "      <td>@KEILOin_DaTrunk I deleted https://t.co/qIhBkn...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79603/796032212407721984-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>377487</td>\n",
       "      <td>377487</td>\n",
       "      <td>798011160532381696-1</td>\n",
       "      <td>0.712648</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>\"RT NYTFashion: How Nasty Gal went from an eBa...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79801/798011160532381696-1.jpg</td>\n",
       "      <td>561</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>423703</td>\n",
       "      <td>423703</td>\n",
       "      <td>801181521679790080-1</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>I hate this nigga lmaooo https://t.co/gPcyJfJESN</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80118/801181521679790080-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0      0      382583        382583  798338609870872577-2  0.774375  0.174701   \n",
       "1      1      443004        443004  802556641057054721-1  0.540009  0.304103   \n",
       "2      2      348885        348885  796032212407721984-1  0.513661  0.322456   \n",
       "3      3      377487        377487  798011160532381696-1  0.712648  0.254173   \n",
       "4      4      423703        423703  801181521679790080-1  0.713677  0.186854   \n",
       "\n",
       "        POS                                               text sent_text  \\\n",
       "0  0.050924  what does it look like i do for a living? (cra...       NEG   \n",
       "1  0.155888  No cheat just skill. #ClikerHeroes https://t.c...       NEG   \n",
       "2  0.163883  @KEILOin_DaTrunk I deleted https://t.co/qIhBkn...       NEG   \n",
       "3  0.033180  \"RT NYTFashion: How Nasty Gal went from an eBa...       NEG   \n",
       "4  0.099468   I hate this nigga lmaooo https://t.co/gPcyJfJESN       NEG   \n",
       "\n",
       "   sent_image                           image_path  image_height  image_width  \n",
       "0           0  data/79833/798338609870872577-2.jpg          1280          722  \n",
       "1           0  data/80255/802556641057054721-1.jpg           707         1366  \n",
       "2           0  data/79603/796032212407721984-1.jpg          1334          750  \n",
       "3           0  data/79801/798011160532381696-1.jpg           561         1000  \n",
       "4           0  data/80118/801181521679790080-1.jpg          1334          750  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sent_image']).head()[df['sent_image'] == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid frequency: sent_image",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets._get_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SENT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets._get_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid frequency: SENT",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7472/2265800979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sent_image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sent_image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset)\u001b[0m\n\u001b[0;32m  10348\u001b[0m         \u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTimedeltaConvertibleTypes\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10349\u001b[0m     ) -> Resampler:\n\u001b[1;32m> 10350\u001b[1;33m         return super().resample(\n\u001b[0m\u001b[0;32m  10351\u001b[0m             \u001b[0mrule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10352\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset)\u001b[0m\n\u001b[0;32m   8124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8125\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8126\u001b[1;33m         return get_resampler(\n\u001b[0m\u001b[0;32m   8127\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8128\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTimeGrouper\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mour\u001b[0m \u001b[0mresampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m     \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeGrouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, freq, closed, label, how, axis, fill_method, limit, loffset, kind, convention, base, origin, offset, **kwargs)\u001b[0m\n\u001b[0;32m   1448\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Unsupported value {convention} for `convention`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1450\u001b[1;33m         \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_offset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[0mend_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"M\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Q\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BA\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BQ\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"W\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid frequency: sent_image"
     ]
    }
   ],
   "source": [
    "df.resample(\"sent_image\")[\"sent_image\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_dfcmoTpVdB3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_image\n",
       "0    0.333333\n",
       "1    0.333333\n",
       "2    0.333333\n",
       "Name: index, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica o balanceamento das classes\n",
    "classes = df.groupby('sent_image')['index'].nunique()/df.shape[0] #Agrupe por index\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "eRrHD1w4VdB4"
   },
   "outputs": [],
   "source": [
    "image_height = 128 #Defina o tamanho  da imagem\n",
    "image_width = 128 #Defina a largura da iamge\n",
    "from tensorflow.keras.preprocessing.image import load_img #carrega funcao para carraegar imagem\n",
    "from tensorflow.keras.preprocessing.image import img_to_array #carrega funcao para converter imagem para array\n",
    "from PIL import Image\n",
    "#Funcao que remove quebra de linha\n",
    "def remove_spaces(cell):  \n",
    "    return cell.replace('\\n',' ')\n",
    "#Converte que carrega a image e depois convertte para array\n",
    "def get_array(image_path):\n",
    "    img = load_img(\"D:\\\\SiDi\\\\Project\\\\Modulo II\\\\dataset\\\\512\" + '/' + f\"{image_path}.jpg\", target_size=(image_height, image_width), color_mode='grayscale')\n",
    "\n",
    "    return img_to_array(img)\n",
    "\n",
    "\n",
    "#Mapeaa os tipos de classes existente nos rotulos de predicoes\n",
    "def to_one_hot(y, class_mapping, num_classes):\n",
    "    y_int = y.map(class_mapping)\n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "#X_text = df['text'].apply(remove_spaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Numero de classes do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fdL7BAx0VdB5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_classes = df['sent_text'].nunique()\n",
    "#Faz o mapeeamento da classe com o id\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_image']))}\n",
    "class_mapping\n",
    "#y_int = df['sent_text'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupamento e Separação por Rotulo da Classe (Sentimento da Imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1863</td>\n",
       "      <td>352154</td>\n",
       "      <td>352154</td>\n",
       "      <td>796184046242066433-2</td>\n",
       "      <td>0.932633</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>0.046466</td>\n",
       "      <td>Can we have this wig back? (Also this was in m...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79618/796184046242066433-2.jpg</td>\n",
       "      <td>710</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index Unnamed: 0 Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0  1863     352154       352154  796184046242066433-2  0.932633  0.020901   \n",
       "\n",
       "        POS                                               text sent_text  \\\n",
       "0  0.046466  Can we have this wig back? (Also this was in m...       NEG   \n",
       "\n",
       "  sent_image                           image_path image_height image_width  \n",
       "0          0  data/79618/796184046242066433-2.jpg          710         750  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLICING_SIZE = 1000\n",
    "neg_df = df.groupby(['sent_image']).get_group(0).sample(n=SLICING_SIZE, ignore_index=True)\n",
    "neu_df = df.groupby(['sent_image']).get_group(1).sample(n=SLICING_SIZE, ignore_index=True)\n",
    "\n",
    "pos_df = df.groupby(['sent_image']).get_group(2).sample(n=SLICING_SIZE, ignore_index=True)\n",
    "\n",
    "\"\"\"for id in neg_df.index[0:1]:\n",
    "    print(id)\n",
    "    test = neg_df.iloc[id].to_frame().T\n",
    "test\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_join_image = []\n",
    "y_join = []\n",
    "\n",
    "image_path = []\n",
    "y_total = []\n",
    "\n",
    "\n",
    "\n",
    "# Negative Class\n",
    "for i in range(0,SLICING_SIZE, 1):\n",
    "    # Negative Class\n",
    "    X_image = neg_df.iloc[i].to_frame().T['image_name'].apply(get_array)\n",
    "    y = to_one_hot(neg_df.iloc[i].to_frame().T['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "\n",
    "    # Positive Class\n",
    "    X_image = neu_df.iloc[i].to_frame().T['image_name'].apply(get_array)\n",
    "    y = to_one_hot(neu_df.iloc[i].to_frame().T['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "    \n",
    "    # Neutro Class\n",
    "    X_image = pos_df.iloc[i].to_frame().T['image_name'].apply(get_array)\n",
    "    y = to_one_hot(pos_df.iloc[i].to_frame().T['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "\n",
    "#X_test_text = pd.Series(X_test_text)\n",
    "X_join_image = pd.Series(X_join_image)\n",
    "y_join = np.array(y_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_join_image = []\n",
    "y_join = []\n",
    "\n",
    "image_path = []\n",
    "y_total = []\n",
    "\n",
    "\n",
    "\n",
    "# Negative Class\n",
    "for i in range(1,1001,1):\n",
    "    X_image = df[i-1:i]['image_name'].apply(get_array)\n",
    "    y = to_one_hot(df[i-1:i]['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "\n",
    "# Positive Class\n",
    "for i in range(4001,5001,1):\n",
    "    X_image = df[i-1:i]['image_name'].apply(get_array)\n",
    "    y = to_one_hot(df[i-1:i]['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "\n",
    "# Neutro Class\n",
    "for i in range(8001,9001,1):\n",
    "    X_image = df[i-1:i]['image_name'].apply(get_array)\n",
    "    y = to_one_hot(df[i-1:i]['sent_image'], class_mapping, num_classes)\n",
    "    X_join_image.extend(X_image)\n",
    "    y_join.extend(y)\n",
    "\n",
    "#X_test_text = pd.Series(X_test_text)\n",
    "X_join_image = pd.Series(X_join_image)\n",
    "y_join = np.array(y_join)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([1000, 1000, 1000], dtype=int64))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_join,  axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 600\n"
     ]
    }
   ],
   "source": [
    "st =  StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1234)\n",
    "for train_index, test_index in st.split(X_join_image, y_join):\n",
    "    X_train_image, X_test_image = X_join_image.iloc[train_index],X_join_image.iloc[test_index]\n",
    "    y_train, y_test = y_join[train_index], y_join[test_index]\n",
    "    print(len(train_index), len(test_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([800, 800, 800], dtype=int64))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([200, 200, 200], dtype=int64))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JsPJ43B9QUP"
   },
   "source": [
    "# Converte de Imagem para Array Numpy - image_to_numpy(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "tVUP1aAPVdB9"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_train_image = image_to_numpy(X_train_image)\n",
    "X_test_image = image_to_numpy(X_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "nf2VBXRxD_An"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_join_image = image_to_numpy(X_join_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjgpvFe91Wg"
   },
   "source": [
    "# (01) - Conjunto de Dados de Validacao - Declara a Classe ImageValidationCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "oW8DDL5zVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 121, 121, 32)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 20, 20, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 15, 15, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " encoded_image (Dense)       (None, 256)               33024     \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,771\n",
      "Trainable params: 72,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbsa2\\multimodal-sentiment-analysis\\multimodal-sentiment-analysis\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='relu', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model_image.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 5/75 [=>............................] - ETA: 2s - loss: 9.9807 - acc: 0.3375 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0467s). Check your callbacks.\n",
      "74/75 [============================>.] - ETA: 0s - loss: 4.8211 - acc: 0.3323\n",
      "accuracy improvement: 0.35333333333333333 (before: -inf), saving to v0.0.1_image-tweet-sent.h5\n",
      "75/75 [==============================] - 3s 34ms/step - loss: 4.8034 - acc: 0.3321 - val_loss: 3.4122 - val_acc: 0.3550\n",
      "Epoch 2/10\n",
      "73/75 [============================>.] - ETA: 0s - loss: 2.8585 - acc: 0.3408\n",
      "accuracy improvement: 0.36333333333333334 (before: 0.35333333333333333), saving to v0.0.1_image-tweet-sent.h5\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 2.8392 - acc: 0.3413 - val_loss: 2.1422 - val_acc: 0.3767\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 2.0020 - acc: 0.3642 - val_loss: 1.6964 - val_acc: 0.3583\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 1.5557 - acc: 0.3875 - val_loss: 1.5930 - val_acc: 0.36331 - acc: 0.387\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.3379 - acc: 0.3996 - val_loss: 1.5654 - val_acc: 0.3517\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.2038 - acc: 0.4412 - val_loss: 1.3862 - val_acc: 0.3950\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 1.0955 - acc: 0.4679 - val_loss: 1.4228 - val_acc: 0.3483\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.0491 - acc: 0.4883 - val_loss: 1.3495 - val_acc: 0.3583\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.9713 - acc: 0.5333 - val_loss: 1.3565 - val_acc: 0.3600\n",
      "Epoch 10/10\n",
      "73/75 [============================>.] - ETA: 0s - loss: 0.9221 - acc: 0.5591\n",
      "accuracy improvement: 0.375 (before: 0.36333333333333334), saving to v0.0.1_image-tweet-sent.h5\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.9251 - acc: 0.5562 - val_loss: 1.3292 - val_acc: 0.3717\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'accuracy'\n",
    "model_file = 'v0.0.1_image-tweet-sent.h5'\n",
    "with tf.device(gpu.name):\n",
    "    for i in range(n_repeats):\n",
    "        checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "        model_image.fit(X_train_image, y_train, epochs=10, batch_size=32,\n",
    "                         validation_data=(X_test_image, y_test)\n",
    "                         ,callbacks = [checkpoint])\n",
    "        exp_history.append(checkpoint.max_metrics)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625\n",
      "0.375\n",
      "0 0.0625 0.375 0.35946839434400824 ness_exp1_single-page_repeat-00.hdf5\n"
     ]
    }
   ],
   "source": [
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.375,\n",
       "  'f1_micro': 0.375,\n",
       "  'f1_macro': 0.35946839434400824,\n",
       "  'f1_binary': 0.3594683943440082,\n",
       "  'kappa': 0.0625}]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image.save('v0.0.2_32-relu-bt4sa-128-image-tweet-sent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2842388153076172\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_image.predict(X_test_image)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.36      0.33       200\n",
      "           1       0.31      0.28      0.29       200\n",
      "           2       0.37      0.34      0.36       200\n",
      "\n",
      "    accuracy                           0.33       600\n",
      "   macro avg       0.33      0.33      0.33       600\n",
      "weighted avg       0.33      0.33      0.33       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "\n",
    "pred_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_class.append(class_mapping[pred[0][0]])\n",
    "    \n",
    "print(classification_report(Y_test, pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "0-2-multi-input-nn-hmm-30-mar-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "multimodal-sentiment-analysis",
   "language": "python",
   "name": "multimodal-sentiment-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
